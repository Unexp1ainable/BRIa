{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"**GRASP-AND-LIFT EEG Detection Project**\n",
				"\n",
				"This project aims to compare different machine learning models in terms of viability for detecting events from EEG signals."
			]
		},
		{
			"cell_type": "code",
			"execution_count": 185,
			"metadata": {
				"_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
				"_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
			},
			"outputs": [],
			"source": [
				"import numpy as np \n",
				"import pandas as pd \n",
				"import matplotlib.pyplot as plt\n",
				"import matplotlib.patches as mpatches"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"**Introduction**"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Training data consists of EEG recordings of subjects performing grasp-and-lift trials.\n",
				"\n",
				"There are 12 subjects in total, 10 series of trials for each subject.\n",
				"\n",
				"Each series recorded 32 EEG channels with sampling rate 500Hz.\n",
				"\n",
				"Training data contains id columns, representing the subject, series, and time at which data point was recorded.\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 186,
			"metadata": {
				"_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
				"_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
				"scrolled": false
			},
			"outputs": [
				{
					"data": {
						"text/html": [
							"<div>\n",
							"<style scoped>\n",
							"    .dataframe tbody tr th:only-of-type {\n",
							"        vertical-align: middle;\n",
							"    }\n",
							"\n",
							"    .dataframe tbody tr th {\n",
							"        vertical-align: top;\n",
							"    }\n",
							"\n",
							"    .dataframe thead th {\n",
							"        text-align: right;\n",
							"    }\n",
							"</style>\n",
							"<table border=\"1\" class=\"dataframe\">\n",
							"  <thead>\n",
							"    <tr style=\"text-align: right;\">\n",
							"      <th></th>\n",
							"      <th>id</th>\n",
							"      <th>Fp1</th>\n",
							"      <th>Fp2</th>\n",
							"      <th>F7</th>\n",
							"      <th>F3</th>\n",
							"      <th>Fz</th>\n",
							"      <th>F4</th>\n",
							"      <th>F8</th>\n",
							"      <th>FC5</th>\n",
							"      <th>FC1</th>\n",
							"      <th>...</th>\n",
							"      <th>P7</th>\n",
							"      <th>P3</th>\n",
							"      <th>Pz</th>\n",
							"      <th>P4</th>\n",
							"      <th>P8</th>\n",
							"      <th>PO9</th>\n",
							"      <th>O1</th>\n",
							"      <th>Oz</th>\n",
							"      <th>O2</th>\n",
							"      <th>PO10</th>\n",
							"    </tr>\n",
							"  </thead>\n",
							"  <tbody>\n",
							"    <tr>\n",
							"      <th>0</th>\n",
							"      <td>subj1_series1_0</td>\n",
							"      <td>-31</td>\n",
							"      <td>363</td>\n",
							"      <td>211</td>\n",
							"      <td>121</td>\n",
							"      <td>211</td>\n",
							"      <td>15</td>\n",
							"      <td>717</td>\n",
							"      <td>279</td>\n",
							"      <td>35</td>\n",
							"      <td>...</td>\n",
							"      <td>536</td>\n",
							"      <td>348</td>\n",
							"      <td>383</td>\n",
							"      <td>105</td>\n",
							"      <td>607</td>\n",
							"      <td>289</td>\n",
							"      <td>459</td>\n",
							"      <td>173</td>\n",
							"      <td>120</td>\n",
							"      <td>704</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>1</th>\n",
							"      <td>subj1_series1_1</td>\n",
							"      <td>-29</td>\n",
							"      <td>342</td>\n",
							"      <td>216</td>\n",
							"      <td>123</td>\n",
							"      <td>222</td>\n",
							"      <td>200</td>\n",
							"      <td>595</td>\n",
							"      <td>329</td>\n",
							"      <td>43</td>\n",
							"      <td>...</td>\n",
							"      <td>529</td>\n",
							"      <td>327</td>\n",
							"      <td>369</td>\n",
							"      <td>78</td>\n",
							"      <td>613</td>\n",
							"      <td>248</td>\n",
							"      <td>409</td>\n",
							"      <td>141</td>\n",
							"      <td>83</td>\n",
							"      <td>737</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>2</th>\n",
							"      <td>subj1_series1_2</td>\n",
							"      <td>-172</td>\n",
							"      <td>278</td>\n",
							"      <td>105</td>\n",
							"      <td>93</td>\n",
							"      <td>222</td>\n",
							"      <td>511</td>\n",
							"      <td>471</td>\n",
							"      <td>280</td>\n",
							"      <td>12</td>\n",
							"      <td>...</td>\n",
							"      <td>511</td>\n",
							"      <td>319</td>\n",
							"      <td>355</td>\n",
							"      <td>66</td>\n",
							"      <td>606</td>\n",
							"      <td>320</td>\n",
							"      <td>440</td>\n",
							"      <td>141</td>\n",
							"      <td>62</td>\n",
							"      <td>677</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>3</th>\n",
							"      <td>subj1_series1_3</td>\n",
							"      <td>-272</td>\n",
							"      <td>263</td>\n",
							"      <td>-52</td>\n",
							"      <td>99</td>\n",
							"      <td>208</td>\n",
							"      <td>511</td>\n",
							"      <td>428</td>\n",
							"      <td>261</td>\n",
							"      <td>27</td>\n",
							"      <td>...</td>\n",
							"      <td>521</td>\n",
							"      <td>336</td>\n",
							"      <td>356</td>\n",
							"      <td>71</td>\n",
							"      <td>568</td>\n",
							"      <td>339</td>\n",
							"      <td>437</td>\n",
							"      <td>139</td>\n",
							"      <td>58</td>\n",
							"      <td>592</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>4</th>\n",
							"      <td>subj1_series1_4</td>\n",
							"      <td>-265</td>\n",
							"      <td>213</td>\n",
							"      <td>-67</td>\n",
							"      <td>99</td>\n",
							"      <td>155</td>\n",
							"      <td>380</td>\n",
							"      <td>476</td>\n",
							"      <td>353</td>\n",
							"      <td>32</td>\n",
							"      <td>...</td>\n",
							"      <td>550</td>\n",
							"      <td>324</td>\n",
							"      <td>346</td>\n",
							"      <td>76</td>\n",
							"      <td>547</td>\n",
							"      <td>343</td>\n",
							"      <td>446</td>\n",
							"      <td>171</td>\n",
							"      <td>67</td>\n",
							"      <td>581</td>\n",
							"    </tr>\n",
							"  </tbody>\n",
							"</table>\n",
							"<p>5 rows Ã— 33 columns</p>\n",
							"</div>"
						],
						"text/plain": [
							"                id  Fp1  Fp2   F7   F3   Fz   F4   F8  FC5  FC1  ...   P7  \\\n",
							"0  subj1_series1_0  -31  363  211  121  211   15  717  279   35  ...  536   \n",
							"1  subj1_series1_1  -29  342  216  123  222  200  595  329   43  ...  529   \n",
							"2  subj1_series1_2 -172  278  105   93  222  511  471  280   12  ...  511   \n",
							"3  subj1_series1_3 -272  263  -52   99  208  511  428  261   27  ...  521   \n",
							"4  subj1_series1_4 -265  213  -67   99  155  380  476  353   32  ...  550   \n",
							"\n",
							"    P3   Pz   P4   P8  PO9   O1   Oz   O2  PO10  \n",
							"0  348  383  105  607  289  459  173  120   704  \n",
							"1  327  369   78  613  248  409  141   83   737  \n",
							"2  319  355   66  606  320  440  141   62   677  \n",
							"3  336  356   71  568  339  437  139   58   592  \n",
							"4  324  346   76  547  343  446  171   67   581  \n",
							"\n",
							"[5 rows x 33 columns]"
						]
					},
					"execution_count": 186,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"train_set_signals = pd.read_csv(\"data/train/subj1_series1_data.csv\")\n",
				"train_set_signals.head()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"The aim is to predict whether a certain event is occuring at a given point.\n",
				"\n",
				"There are 6 events. If an event occured at a given point is represented by 1, 0 otherwise.      \n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 187,
			"metadata": {
				"_uuid": "e6fdf2790a2ac641decf5989897373021f3b6555",
				"scrolled": true
			},
			"outputs": [
				{
					"data": {
						"text/html": [
							"<div>\n",
							"<style scoped>\n",
							"    .dataframe tbody tr th:only-of-type {\n",
							"        vertical-align: middle;\n",
							"    }\n",
							"\n",
							"    .dataframe tbody tr th {\n",
							"        vertical-align: top;\n",
							"    }\n",
							"\n",
							"    .dataframe thead th {\n",
							"        text-align: right;\n",
							"    }\n",
							"</style>\n",
							"<table border=\"1\" class=\"dataframe\">\n",
							"  <thead>\n",
							"    <tr style=\"text-align: right;\">\n",
							"      <th></th>\n",
							"      <th>id</th>\n",
							"      <th>HandStart</th>\n",
							"      <th>FirstDigitTouch</th>\n",
							"      <th>BothStartLoadPhase</th>\n",
							"      <th>LiftOff</th>\n",
							"      <th>Replace</th>\n",
							"      <th>BothReleased</th>\n",
							"    </tr>\n",
							"  </thead>\n",
							"  <tbody>\n",
							"    <tr>\n",
							"      <th>0</th>\n",
							"      <td>subj1_series1_0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>1</th>\n",
							"      <td>subj1_series1_1</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>2</th>\n",
							"      <td>subj1_series1_2</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>3</th>\n",
							"      <td>subj1_series1_3</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>4</th>\n",
							"      <td>subj1_series1_4</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"      <td>0</td>\n",
							"    </tr>\n",
							"  </tbody>\n",
							"</table>\n",
							"</div>"
						],
						"text/plain": [
							"                id  HandStart  FirstDigitTouch  BothStartLoadPhase  LiftOff  \\\n",
							"0  subj1_series1_0          0                0                   0        0   \n",
							"1  subj1_series1_1          0                0                   0        0   \n",
							"2  subj1_series1_2          0                0                   0        0   \n",
							"3  subj1_series1_3          0                0                   0        0   \n",
							"4  subj1_series1_4          0                0                   0        0   \n",
							"\n",
							"   Replace  BothReleased  \n",
							"0        0             0  \n",
							"1        0             0  \n",
							"2        0             0  \n",
							"3        0             0  \n",
							"4        0             0  "
						]
					},
					"execution_count": 187,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"train_set_labels = pd.read_csv(\"data/train/subj1_series1_events.csv\")\n",
				"train_set_labels.head()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Setup for visualizations"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 188,
			"metadata": {
				"_uuid": "5363122b47e28f5d0f7b8af774fcf8814cf71e57"
			},
			"outputs": [],
			"source": [
				"labels = train_set_labels.columns.drop('id')\n",
				"labelNames = labels.values"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 189,
			"metadata": {
				"_uuid": "58286dcc970cdfdd6b548a8ea397a3c7cc200444"
			},
			"outputs": [],
			"source": [
				"train_set_complete = pd.concat([train_set_signals,train_set_labels], axis=1)\n",
				"train_set_complete.insert(0, \"order\", range(0, len(train_set_complete)))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 190,
			"metadata": {
				"_uuid": "6cbf2d4f8971f71ffbeffc8b2c1c9b8814710a9f"
			},
			"outputs": [],
			"source": [
				"def highlight(indices,ax,color):\n",
				"    i=0\n",
				"    while i<len(indices):\n",
				"        ax.axvspan(indices[i]-0.5, indices[i]+0.5, facecolor=color, edgecolor='none', alpha=.4)\n",
				"        i+=1      \n",
				"    "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 191,
			"metadata": {},
			"outputs": [],
			"source": [
				"def vizualize_predictions(signals, predictions, expected, labelName, limit=2000): \n",
				"    #0-31\n",
				"    signalIndex = 10\n",
				"    \n",
				"    #Relevant only for multilabel predictions, else is always 0\n",
				"    labelIndex = 0\n",
				"                \n",
				"    signals = pd.DataFrame(data=np.array(signals))\n",
				"    axis = signals[signals.columns[signalIndex]].iloc[0:limit].plot(figsize=(20,4))  \n",
				"        \n",
				"    expected = pd.DataFrame(data = expected)    \n",
				"    predictions = pd.DataFrame(data = np.around(predictions))\n",
				"    \n",
				"    expectedCropped = expected.iloc[0:limit,]\n",
				"    predictionsCropped = predictions.iloc[0:limit,]\n",
				"    \n",
				"    highlight(expectedCropped[expectedCropped.iloc[:,labelIndex]==1].index, axis, \"red\")\n",
				"    highlight(predictionsCropped[predictionsCropped.iloc[:,labelIndex]==1].index, axis, \"black\")\n",
				"    \n",
				"    red_patch = mpatches.Patch(color='red', label='Expected event')\n",
				"    black_patch = mpatches.Patch(color='black', label='Predicted event')\n",
				"    plt.legend(handles=[red_patch, black_patch])\n",
				"\n",
				"    plt.title(labelName)\n",
				"    plt.show()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Helper methods for loading data\n",
				"\n",
				"Features are standartized by removing the mean and scaling to unit variance\n",
				"\n",
				"Further preprocessing can be done in *prepare_signals* function"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 192,
			"metadata": {},
			"outputs": [],
			"source": [
				"import math\n",
				"from sklearn.preprocessing import StandardScaler\n",
				"\n",
				"def load_train_data(subject, series):\n",
				"    train_set_signals = pd.read_csv(f\"data/train/subj{subject}_series{series}_data.csv\")\n",
				"    train_set_labels = pd.read_csv(f\"data/train/subj{subject}_series{series}_events.csv\")\n",
				"    return train_set_signals, train_set_labels\n",
				"\n",
				"def prepare_labels(data):    \n",
				"    return data.drop(\"id\", axis=1)\n",
				"    \n",
				"def prepare_signals(data):\n",
				"    data = data.drop(\"id\", axis=1)\n",
				"    columns = data.columns      \n",
				"    \n",
				"    #Preprocessing    \n",
				"    scaler = StandardScaler() \n",
				"    data =np.asarray(data.astype(float))\n",
				"    data = scaler.fit_transform(data)\n",
				"    data = pd.DataFrame(data, columns=columns) \n",
				"    \n",
				"    return data\n",
				"    \n",
				"def load_train_data_prepared(subject, series):    \n",
				"    signals, labels = load_train_data(subject,series)    \n",
				"    return prepare_signals(signals), prepare_labels(labels)   \n",
				"\n",
				"\n",
				"\n",
				"\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Helper for printing success rates for given predictions and expected values"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 211,
			"metadata": {},
			"outputs": [],
			"source": [
				"def rd(x):\n",
				"        return round(x)\n",
				"\n",
				"def printSucc(predictions, expected, dataLabel):\n",
				"    #success counters\n",
				"    succ = 0\n",
				"    onesTotal = 0\n",
				"    onesSucc = 0\n",
				"    \n",
				"    #Compute successes in data\n",
				"    for i in range(0, len(predictions)):    \n",
				"        if(np.array_equal(list(map(rd, predictions[i])),expected[i])):\n",
				"            succ+=1\n",
				"\n",
				"        if 1 == expected[i]:\n",
				"            onesTotal += 1           \n",
				"            if(round(predictions[i][0]) == 1):\n",
				"                onesSucc +=1           \n",
				"\n",
				"    print(dataLabel, \"success\", \"---\",\"TOTAL =\", \"{:0.4f}\".format(succ/len(predictions)), \"|||\",\"EVENT =\",\"{:0.4f}\".format(onesSucc/onesTotal) ,\"(\", onesSucc, \"/\",onesTotal, \")\")    \n",
				"    \n",
				"    return succ/len(predictions), onesSucc/onesTotal"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"**RECURRENT NEURAL NETWORK**\n",
				"\n",
				"RNN with LSTM, dropout and activation layers\n",
				"\n",
				"* Adam optimizer\n",
				"* Binary crossentropy loss \n",
				"* Sigmoid activation layer"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Transform 2D dataset to 3D for LSTM layer - add floating window of *look_back* length"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 194,
			"metadata": {},
			"outputs": [],
			"source": [
				"def create_sequences(dataset,labels, look_back=1):\n",
				"    dataX = []\n",
				"    dataY = labels[look_back:]\n",
				"    for i in range(len(dataset)-look_back):\n",
				"        dataX.append(dataset[i:(i+look_back), ])\n",
				"    return np.array(dataX), np.array(dataY)\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Tests given rnn model on predicting label or more labels from testing data.\n",
				"\n",
				"Provides visualisations and success rates.\n",
				"\n",
				"\n",
				"\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 195,
			"metadata": {},
			"outputs": [],
			"source": [
				"#data are downsampled, each 15th data point is taken\n",
				"DOWNSAMPLING = 15\n",
				"LOOK_BACK = 35\n",
				"BATCH_SIZE = 512\n",
				"\n",
				"#Iterations on stateful model, epochs on non-stateful\n",
				"EPOCHS = 30\n",
				"ITERATIONS = 1\n",
				"STATEFUL = False\n",
				"SHUFFLE = not STATEFUL\n",
				"VERBOSE = 0    "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 196,
			"metadata": {},
			"outputs": [],
			"source": [
				"def evaluate_rnn(subject, model, label, draw):\n",
				"    #Last (8th) series is used as testing data\n",
				"    test_signals, test_labels = load_train_data_prepared(subject=subject,series=8)\n",
				"    \n",
				"    #Creating sequences for lstm layer\n",
				"    X_test_signals, X_test_labels = create_sequences(\n",
				"        test_signals.values[::DOWNSAMPLING],\n",
				"        test_labels.values[::DOWNSAMPLING],\n",
				"        look_back=LOOK_BACK\n",
				"    )\n",
				"    #Selecting only desired labels\n",
				"    X_test_labels = X_test_labels[:,label] \n",
				"\n",
				"    #Last few data points that do not fit batch size are omitted \n",
				"    croppedSize = math.floor(len(X_test_signals)/BATCH_SIZE)*BATCH_SIZE    \n",
				"\n",
				"    #Prediction for testing data\n",
				"    predictions = model.predict(X_test_signals[0:croppedSize], batch_size=BATCH_SIZE)\n",
				"    expected = X_test_labels[0:croppedSize]\n",
				"    \n",
				"    #Selecting only desired labels   \n",
				"    labelsPredicted = len(predictions[0])\n",
				"    if(labelsPredicted == 1):\n",
				"        predictions = predictions[:,0:1]\n",
				"    else: #6 labels predicted    \n",
				"        predictions = predictions[:,label] \n",
				"    \n",
				"            \n",
				"    #Success rate printing    \n",
				"    totalPercent, onesPercent = printSucc(predictions,expected, dataLabel=\"Testing\")\n",
				"    \n",
				"    #Vizualization\n",
				"    if(draw):\n",
				"        vizualize_predictions(\n",
				"            test_signals.values[::DOWNSAMPLING][LOOK_BACK:croppedSize+LOOK_BACK:],\n",
				"            predictions,\n",
				"            expected,\n",
				"            labelName = labelNames[label],  \n",
				"            limit = 1000\n",
				"        )\n",
				"    \n",
				"    return totalPercent, onesPercent    "
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Training of a single model for a single or more subjects.\n",
				"\n",
				"Uses series 1-7 (leaves series 8 for testing)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 197,
			"metadata": {},
			"outputs": [],
			"source": [
				"from keras.models import Sequential\n",
				"from keras.layers import Dense, Activation, LSTM, Dropout\n",
				"\n",
				"def train_rnn(subjects, labelToTrain, model, callbacks): \n",
				"    #For specified subjects\n",
				"    for subject in subjects:\n",
				"        #For series 1-7 \n",
				"        for j in range(1,8):    # TODO change\n",
				"            signals, labels = load_train_data_prepared(subject = subject,series = j) \n",
				"            #Create sequences\n",
				"            X_train_signals, X_train_labels = create_sequences(\n",
				"                signals.iloc[::DOWNSAMPLING].values,\n",
				"                labels.iloc[::DOWNSAMPLING].values,\n",
				"                look_back=LOOK_BACK       \n",
				"            )        \n",
				"\n",
				"            X_train_labels = X_train_labels[:,labelToTrain]\n",
				"            croppedSize = math.floor(len(X_train_signals)/BATCH_SIZE)*BATCH_SIZE        \n",
				"            #Train model on relevant label (calling fit repeatedly in keras doesnt reset the model)\n",
				"            model.fit(\n",
				"                X_train_signals[0:croppedSize],\n",
				"                X_train_labels[0:croppedSize],\n",
				"                epochs=EPOCHS,\n",
				"                batch_size=BATCH_SIZE,\n",
				"                shuffle=SHUFFLE,\n",
				"                verbose=VERBOSE,\n",
				"                callbacks=callbacks\n",
				"            )            \n",
				"            \n",
				"            model.reset_states()\n",
				"    \n",
				"    \n",
				"    print(\"FITTING DONE\")\n",
				"    return model"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Training of model for given subjects and evaluating it.\n",
				"\n",
				"Evaluating each label success rate separarely and averaging them. Random behaviour has 50% success rate.\n",
				"\n",
				"For given subject, we use first 7 series as training data and 8'th series as test data. "
			]
		},
		{
			"cell_type": "code",
			"execution_count": 198,
			"metadata": {},
			"outputs": [],
			"source": [
				"def rnn_validation(model, trainSeparateLabels, callbacks, draw=False, subjectToEvaluateOn = 1, label=0):\n",
				"    totalPercentages = []\n",
				"    onesPercentages = []   \n",
				"    \n",
				"    print(labelNames[label],\"label model evaluation\")\n",
				"    \n",
				"    total, ones = evaluate_rnn(subjectToEvaluateOn, model, label, draw = draw)\n",
				"    totalPercentages.append(total)\n",
				"    onesPercentages.append(ones)        \n",
				"\n",
				"    print(\"SUMMARY\")\n",
				"    print(\"TOTAL :\", sum(totalPercentages)/len(totalPercentages))\n",
				"    print(\"EVENTS :\", sum(onesPercentages)/len(onesPercentages))"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"RNN configuration"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 199,
			"metadata": {},
			"outputs": [],
			"source": [
				"from keras.callbacks import EarlyStopping\n",
				"\n",
				"callbacks=[EarlyStopping(monitor=\"accuracy\", verbose=0, patience=10, restore_best_weights=True)]"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Basic model, training all labels at once for single subject"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"Stacked model, training all labels separately for single subject"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 200,
			"metadata": {},
			"outputs": [],
			"source": [
				"LABEL = 0"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 201,
			"metadata": {},
			"outputs": [],
			"source": [
				"model = Sequential()\n",
				"model.add(LSTM(50,batch_input_shape=(BATCH_SIZE,LOOK_BACK,32), return_sequences=True, stateful=STATEFUL, dropout=0.5, activation=\"softsign\")) \n",
				"model.add(LSTM(50, return_sequences=False, stateful=STATEFUL, dropout=0.5, activation=\"softsign\"))     \n",
				"model.add(Dense(1, activation=\"sigmoid\"))\n",
				"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 202,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"FITTING DONE\n"
					]
				}
			],
			"source": [
				"    #Separate models for training all labels separately\n",
				"model = train_rnn(  \n",
				"    subjects = [1],\n",
				"    labelToTrain=LABEL,\n",
				"    model = model,\n",
				"    callbacks=callbacks\n",
				"    )"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 212,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"HandStart label model evaluation\n",
						"16/16 [==============================] - 0s 21ms/step\n"
					]
				},
				{
					"ename": "TypeError",
					"evalue": "type numpy.bool_ doesn't define __round__ method",
					"output_type": "error",
					"traceback": [
						"\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
						"\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
						"Cell \u001b[0;32mIn [212], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rnn_validation(\n\u001b[1;32m      2\u001b[0m                model \u001b[39m=\u001b[39;49m model,\n\u001b[1;32m      3\u001b[0m                trainSeparateLabels\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      4\u001b[0m                draw\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      5\u001b[0m                subjectToEvaluateOn\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m                callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m      7\u001b[0m                label\u001b[39m=\u001b[39;49mLABEL\n\u001b[1;32m      8\u001b[0m               )\n",
						"Cell \u001b[0;32mIn [198], line 7\u001b[0m, in \u001b[0;36mrnn_validation\u001b[0;34m(model, trainSeparateLabels, callbacks, draw, subjectToEvaluateOn, label)\u001b[0m\n\u001b[1;32m      3\u001b[0m onesPercentages \u001b[39m=\u001b[39m []   \n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(labelNames[label],\u001b[39m\"\u001b[39m\u001b[39mlabel model evaluation\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m total, ones \u001b[39m=\u001b[39m evaluate_rnn(subjectToEvaluateOn, model, label, draw \u001b[39m=\u001b[39;49m draw)\n\u001b[1;32m      8\u001b[0m totalPercentages\u001b[39m.\u001b[39mappend(total)\n\u001b[1;32m      9\u001b[0m onesPercentages\u001b[39m.\u001b[39mappend(ones)        \n",
						"Cell \u001b[0;32mIn [196], line 30\u001b[0m, in \u001b[0;36mevaluate_rnn\u001b[0;34m(subject, model, label, draw)\u001b[0m\n\u001b[1;32m     26\u001b[0m     predictions \u001b[39m=\u001b[39m predictions[:,label] \n\u001b[1;32m     29\u001b[0m \u001b[39m#Success rate printing    \u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m totalPercent, onesPercent \u001b[39m=\u001b[39m printSucc(predictions,expected, dataLabel\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTesting\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     32\u001b[0m \u001b[39m#Vizualization\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mif\u001b[39;00m(draw):\n",
						"Cell \u001b[0;32mIn [211], line 17\u001b[0m, in \u001b[0;36mprintSucc\u001b[0;34m(predictions, expected, dataLabel)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m==\u001b[39m expected[i]:\n\u001b[1;32m     16\u001b[0m         onesTotal \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m           \n\u001b[0;32m---> 17\u001b[0m         \u001b[39mif\u001b[39;00m(\u001b[39mround\u001b[39;49m(predictions[i][\u001b[39m0\u001b[39;49m] \u001b[39m==\u001b[39;49m \u001b[39m1\u001b[39;49m)):\n\u001b[1;32m     18\u001b[0m             onesSucc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m           \n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(dataLabel, \u001b[39m\"\u001b[39m\u001b[39msuccess\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m---\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mTOTAL =\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m{:0.4f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(succ\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(predictions)), \u001b[39m\"\u001b[39m\u001b[39m|||\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mEVENT =\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m{:0.4f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(onesSucc\u001b[39m/\u001b[39monesTotal) ,\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m\"\u001b[39m, onesSucc, \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m,onesTotal, \u001b[39m\"\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)    \n",
						"\u001b[0;31mTypeError\u001b[0m: type numpy.bool_ doesn't define __round__ method"
					]
				}
			],
			"source": [
				"rnn_validation(\n",
				"               model = model,\n",
				"               trainSeparateLabels=True,\n",
				"               draw=True,\n",
				"               subjectToEvaluateOn=10,\n",
				"               callbacks=callbacks,\n",
				"               label=LABEL\n",
				"              )"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": []
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "tf",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.9.15"
		},
		"vscode": {
			"interpreter": {
				"hash": "9f518bb80e495597f8cd57757a0d950913107f49333a0edca4b6d2d4e705514f"
			}
		}
	},
	"nbformat": 4,
	"nbformat_minor": 1
}
